{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df1d4a-ea79-4324-9a8e-8a3687ff69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0bf84-2937-4277-a5cd-59e607f43988",
   "metadata": {},
   "source": [
    "## Initialize SAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323418da-0134-4dc2-8691-c0304b7a1604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 403 layers, 80,850,178 parameters, 80,850,178 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(403, 80850178, 80850178, 0.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import SAM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the model\n",
    "model = SAM('sam2.1_b.pt')\n",
    "\n",
    "# display model info\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9674b8-8b66-426d-a8c4-5021e60b0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url - https://ultralytics.com/images/bus.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f57e9ce-513d-4e89-827a-e7cd88572b0b",
   "metadata": {},
   "source": [
    "## Segment Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "964ade8b-bbc6-4d97-b48f-5df355650f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_image.jpg: 1024x1024 1 0, 340.4ms\n",
      "Speed: 34.1ms preprocess, 340.4ms inference, 13.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# define bounding box regions\n",
    "bboxes = [[55, 400, 230, 900]]\n",
    "\n",
    "image_path = 'test_image.jpg'\n",
    "results = model(image_path, bboxes=bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2cb03c7-a5b4-49db-96ad-081894a11e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae3b7bf-dcec-4475-aeab-a9980acc1448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_image.jpg: 1024x1024 1 0, 388.6ms\n",
      "Speed: 8.1ms preprocess, 388.6ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# define single points\n",
    "points = [[350, 370]]\n",
    "results = model(image_path, points=points, labels=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51336c96-ad06-4fee-913c-ed8b24d7a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f18aa5b-7455-48b4-9724-cef8762043bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_image.jpg: 1024x1024 1 0, 1 1, 319.8ms\n",
      "Speed: 12.7ms preprocess, 319.8ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# define multiple points\n",
    "points = [[350, 370], [100, 650]]\n",
    "results = model(image_path, points=points, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c7319c0-07d3-4aaa-876d-dd8c687dd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a276cb7-3d14-41d6-9603-c673a8f2d8c5",
   "metadata": {},
   "source": [
    "## Extract BBox Image from the Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48951306-2288-45bb-aa9a-5c48b2e6cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37857baf-ff0b-4092-bd1c-886fe0759155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 17., 232., 800., 726.],\n",
       "        [ 57., 401., 205., 896.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef7578a-dc8c-47b7-9f8d-f87ccd8d85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    if hasattr(result, 'boxes') and result.boxes is not None:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy() if isinstance(result.boxes.xyxy, torch.Tensor) else np.array(result.boxes.xyxy)\n",
    "\n",
    "        # iterate through the bounding boxes\n",
    "        for j, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box[:4])\n",
    "\n",
    "            cropped_img = image[y1:y2, x1: x2]\n",
    "\n",
    "            # show the image\n",
    "            cv2.imshow(f\"Cropped Image {i}_{j}\", cropped_img)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510f1be-9585-49db-8f9c-a423ca5454a2",
   "metadata": {},
   "source": [
    "## Segment Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7cadf2-f54f-49d3-9d15-c86fbf5c5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.sam import SAM2VideoPredictor\n",
    "\n",
    "# define model parameters\n",
    "overrides = dict(conf=0.25, task='segment', mode='predict', imgsz=1024, model='sam2.1_b.pt')\n",
    "\n",
    "predictor = SAM2VideoPredictor(overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67377c6c-1ac0-47aa-bc28-73ca07c29acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics 8.3.91  Python-3.12.3 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4070, 12282MiB)\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 178.3ms\n",
      "video 1/1 (frame 2/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 133.1ms\n",
      "video 1/1 (frame 3/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 120.7ms\n",
      "video 1/1 (frame 4/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 125.5ms\n",
      "video 1/1 (frame 5/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 132.5ms\n",
      "video 1/1 (frame 6/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.0ms\n",
      "video 1/1 (frame 7/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 151.5ms\n",
      "video 1/1 (frame 8/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 160.3ms\n",
      "video 1/1 (frame 9/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 148.5ms\n",
      "video 1/1 (frame 10/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.2ms\n",
      "video 1/1 (frame 11/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.5ms\n",
      "video 1/1 (frame 12/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.5ms\n",
      "video 1/1 (frame 13/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.4ms\n",
      "video 1/1 (frame 14/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.1ms\n",
      "video 1/1 (frame 15/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.3ms\n",
      "video 1/1 (frame 16/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.2ms\n",
      "video 1/1 (frame 17/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.4ms\n",
      "video 1/1 (frame 18/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.9ms\n",
      "video 1/1 (frame 19/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.6ms\n",
      "video 1/1 (frame 20/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.8ms\n",
      "video 1/1 (frame 21/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.8ms\n",
      "video 1/1 (frame 22/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 148.1ms\n",
      "video 1/1 (frame 23/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.2ms\n",
      "video 1/1 (frame 24/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 148.0ms\n",
      "video 1/1 (frame 25/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 149.0ms\n",
      "video 1/1 (frame 26/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 149.9ms\n",
      "video 1/1 (frame 27/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 174.6ms\n",
      "video 1/1 (frame 28/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.3ms\n",
      "video 1/1 (frame 29/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.7ms\n",
      "video 1/1 (frame 30/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.7ms\n",
      "video 1/1 (frame 31/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.4ms\n",
      "video 1/1 (frame 32/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 164.3ms\n",
      "video 1/1 (frame 33/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.2ms\n",
      "video 1/1 (frame 34/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 148.1ms\n",
      "video 1/1 (frame 35/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.8ms\n",
      "video 1/1 (frame 36/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.6ms\n",
      "video 1/1 (frame 37/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.5ms\n",
      "video 1/1 (frame 38/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.3ms\n",
      "video 1/1 (frame 39/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.7ms\n",
      "video 1/1 (frame 40/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.5ms\n",
      "video 1/1 (frame 41/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 151.6ms\n",
      "video 1/1 (frame 42/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.0ms\n",
      "video 1/1 (frame 43/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.5ms\n",
      "video 1/1 (frame 44/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 148.3ms\n",
      "video 1/1 (frame 45/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.6ms\n",
      "video 1/1 (frame 46/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.3ms\n",
      "video 1/1 (frame 47/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.7ms\n",
      "video 1/1 (frame 48/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.7ms\n",
      "video 1/1 (frame 49/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 150.7ms\n",
      "video 1/1 (frame 50/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 146.0ms\n",
      "video 1/1 (frame 51/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.8ms\n",
      "video 1/1 (frame 52/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.0ms\n",
      "video 1/1 (frame 53/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.5ms\n",
      "video 1/1 (frame 54/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 147.0ms\n",
      "video 1/1 (frame 55/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 143.9ms\n",
      "video 1/1 (frame 56/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.4ms\n",
      "video 1/1 (frame 57/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 144.3ms\n",
      "video 1/1 (frame 58/58) D:\\notebooks\\temp projects\\youtube\\Image & Video Segmentation using SAM2.1\\test_video.mp4: 1024x1024 1 0, 145.4ms\n",
      "Speed: 4.3ms preprocess, 146.9ms inference, 0.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "video_path = 'test_video.mp4'\n",
    "\n",
    "results = predictor(source=video_path, points=[900, 820], labels=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bea90-0e28-476d-9029-969dc923e4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
